# Simplified Dockerfile for Render.com deployment with OpenAI
# No Ollama needed - much lighter and faster!

FROM python:3.11-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1 \
    PORT=9000

# Install minimal system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY main.py .
COPY src/ ./src/
COPY data/ ./data/

# Create necessary directories
RUN mkdir -p /app/docs /app/logs

# Expose port (Render will set PORT env var)
EXPOSE 9000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:${PORT:-9000}/docs || exit 1

# Run document ingestion then start the app
# Note: Render allows persistent disks, so docs/ will persist between deploys
CMD python src/ingest.py && \
    uvicorn main:app --host 0.0.0.0 --port ${PORT:-9000} --log-level info
